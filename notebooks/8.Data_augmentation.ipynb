{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook analyse data from a range of static and dynamic predictors to develop a spatio-temporal analysis of use of outside natural spaces. Using a range of static and dynamic features, a machine learning model is trained to estimate (predict) the number of visitors in outside natural spaces based on people monitoring sites at specific locations**\n",
    "\n",
    ". People counter data for specific locations (Natural England, North Downs Way, River and Canal Trust)\n",
    "\n",
    ". Strava Metro (pedestrian) activity data\n",
    "\n",
    ". Socio-economic and demographic features \n",
    "\n",
    ". Open Street Map features\n",
    "\n",
    ". Rural Urban classification features \n",
    "\n",
    ". Living England Habitat Map features\n",
    "\n",
    ". Accessible Green and Blue infrastructure features\n",
    "\n",
    ". Historical weather features \n",
    "\n",
    ". People and Natural Survey features \n",
    "\n",
    "\n",
    "\n",
    "1. <a href='#dest_1'>Import packages</a>\n",
    "\n",
    "2. <a href='#dest_2'>Config file</a>\n",
    "\n",
    "3. <a href='#dest_3'>Utility functions</a>\n",
    "\n",
    "4. <a href='#dest_4'>Load data</a>\n",
    "\n",
    "5. <a href='#dest_5'>Univariate model: Counter data vs Strava data</a>\n",
    "\n",
    "6. <a href='#dest_6'>Static and dynamic features merging</a>\n",
    "\n",
    "7. <a href='#dest_7'>Multivariate Regression model</a> \n",
    "\n",
    "\n",
    "https://github.com/pycaret/pycaret/blob/master/examples/Pycaret_2.1_Regression_EmployeePerformance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**\n",
    "<a id='dest_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_packages import *\n",
    "from model_config import *\n",
    "from model_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD  DATASETS\n",
    "\n",
    "<a id='dest_4'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Census 2011 data- Socio-economic and demographic features\n",
    "\n",
    "This is an Open dataset from https://www.nomisweb.co.uk\n",
    "\n",
    "The dataset has been prepared in a separate notebook (Census features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demg=pd.read_pickle(census_locn_file)\n",
    "# Area of each buffer region around the counter sites.\n",
    "# Buffer zone is 5km radius around each site:pi*r^2: 78.5 sq km\n",
    "area_sites_oa=df_demg.groupby('counter')['area_sq_km'].sum().reset_index()\n",
    "\n",
    "\n",
    "df_demg['Density (number of persons per sq_km)']=100*df_demg['Density (number of persons per hectare)']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. People monitoring counter data\n",
    "\n",
    "**Target variable in the model (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the counter sites\n",
    "\n",
    "#Natural england sites\n",
    "counter_ne=assgn_lat_lon(ne_countr_locn_file,'counter')\n",
    "\n",
    "#North Downs way sites\n",
    "counter_nd=assgn_lat_lon(ndw_countr_locn_file,'counter')\n",
    "\n",
    "\n",
    "# 01-2023- No training data available for these sites-\n",
    "# Canal River Trust sites\n",
    "counter_cr=assgn_lat_lon(crt_countr_locn_file,'Counter')\\\n",
    "[['Counter','latitude','longitude','geometry']]\n",
    "counter_cr.rename(columns={'Counter':'counter'},inplace=True)\n",
    "all_counter_location=pd.concat([counter_ne,counter_nd,counter_cr]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing of counter data- Target variable\n",
    "\n",
    "df_count_ne=prepare_counter_data(ne_strava_data_file,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# North Downs Way data prep\n",
    "df_count_nd=prepare_counter_data(ndw_strava_data_file,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation of the time series data\n",
    "\n",
    "df_count_line=df_count_ne.copy().sort_index().reset_index()\n",
    "\n",
    "fig = px.line(df_count_line, x='Date', y=df_count_line.columns,\n",
    "              hover_data={\"Date\": \"|%B %d, %Y\"},\n",
    "              title='People counter',markers=True)\n",
    "fig.update_xaxes(dtick=\"M1\",tickformat=\"%b\\n%Y\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_line_val=df_count_nd.copy().sort_index().reset_index()\n",
    "\n",
    "fig = px.bar(df_count_line_val, x='Date', y=df_count_line_val.columns,\n",
    "              hover_data={\"Date\": \"|%B %d, %Y\"},\n",
    "              title='People counter')\n",
    "fig.update_xaxes(dtick=\"M1\",tickformat=\"%b\\n%Y\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Open Street Map data\n",
    "\n",
    "We obtain points of interest around the counter locations using openstreet map\n",
    "\n",
    "The following takes a long time to process so we have saved the data locally for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data saved locally and create if doesnt exist, repeated for each counter data set\n",
    "\n",
    "if os.path.isfile(data_folder+'ne_pois_df.pkl') == True:\n",
    "    print(\"File already exists\")\n",
    "    ne_pois_df= pd.read_pickle(data_folder+'ne_pois_df.pkl')\n",
    "else: \n",
    "    ne_pois_df=get_pois(ne_countr_locn_file,'ne')\n",
    "\n",
    "\n",
    "if os.path.isfile(data_folder+'dw_pois_df.pkl') == True:\n",
    "    print(\"File already exists\")\n",
    "    nd_pois_df= pd.read_pickle(data_folder+'dw_pois_df.pkl')\n",
    "else: \n",
    "    nd_pois_df=get_pois(ndw_countr_locn_file,'dw')\n",
    "\n",
    "\n",
    "if os.path.isfile(data_folder+'rvr_cnl_pois_df.pkl') == True:\n",
    "    print(\"File already exists\")\n",
    "    cr_pois_df= pd.read_pickle(data_folder+'rvr_cnl_pois_df.pkl')\n",
    "else: \n",
    "    cr_pois_df=get_pois(crt_countr_locn_file,'rvr_cnl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All pois across all sites\n",
    "df_pois_all_sites=pd.concat([ne_pois_df,nd_pois_df,cr_pois_df]).dropna(axis=1).reset_index(drop=True)\n",
    "\n",
    "# Merge it with buffer zone areas for each site\n",
    "df_pois_all_sites=df_pois_all_sites.merge(area_sites_oa.rename(columns={'counter':'site'}),on=['site'],how='inner')\n",
    "\n",
    "\n",
    "num_cols=[x for x in df_pois_all_sites.columns if x not in ['area_sq_km','site']]\n",
    "\n",
    "# Density of pois\n",
    "df_pois_all_sites[num_cols]=df_pois_all_sites[num_cols].div(df_pois_all_sites['area_sq_km'],axis=0)\n",
    "\n",
    "del df_pois_all_sites['area_sq_km']\n",
    "\n",
    "df_pois_all_sites.to_pickle(data_folder+'pois_data_all_sites.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socioeconomic and Demographic Data Augmentation\n",
    "\n",
    "Socioeconomic and demographic features taken from the census have spatial correlations and we need to infer the correlated features (using Factor Analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define collecive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define collective features\n",
    "\n",
    "df_demg['3+ people in household']=df_demg[['3 people in household','4 people in household',\\\n",
    "                                           '5 people in household','6 people in household',\\\n",
    "                                           '7 people in household','8 or more people in household']].sum(axis=1)\n",
    "\n",
    "\n",
    "df_demg['1-2 people in household']=df_demg[['1 person in household','2 people in household']].sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "household_occupancy_ftrs=['1-2 people in household','3+ people in household']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_demg['Age group 0-25']=df_demg[['Age 0 to 4','Age 5 to 7','Age 8 to 9', 'Age 10 to 14',\\\n",
    "                                   'Age 15', 'Age 16 to 17','Age 18 to 19', 'Age 20 to 24']].sum(axis=1)\n",
    "\n",
    "df_demg['Age group 25-65']=df_demg[['Age 25 to 29', 'Age 30 to 44','Age 45 to 59', 'Age 60 to 64']].sum(axis=1)\n",
    "\n",
    "\n",
    "df_demg['Age group 65+']=df_demg[['Age 65 to 74', 'Age 75 to 84','Age 85 to 89', 'Age 90 and over']].sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "age_ftrs=['Age group 0-25','Age group 25-65','Age group 65+']\n",
    "\n",
    "\n",
    "\n",
    "df_demg['Household is deprived in at least 1 dimension']=df_demg[['Household is deprived in 1 dimension',\\\n",
    "                                                                  'Household is deprived in 2 dimensions',\\\n",
    "                                                                  'Household is deprived in 3 dimensions',\\\n",
    "                                                                  'Household is deprived in 4 dimensions']].\\\n",
    "sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "deprivation_ftrs=['Household is not deprived in any dimension','Household is deprived in at least 1 dimension']\n",
    "\n",
    "people_density_ftrs=['Density (number of persons per sq_km)']\n",
    "\n",
    "\n",
    "\n",
    "df_demg['Unemployed_population']=df_demg[['Unemployed: Age 16 to 24','Unemployed: Age 50 to 74',\\\n",
    "                                          'Unemployed: Never worked','Long-term unemployed']].sum(axis=1)\n",
    "\n",
    "econominc_activity_ftrs=['Economically active', 'Economically Inactive','Unemployed_population']\n",
    "\n",
    "\n",
    "df_demg['Population in Good Health']=df_demg[['Very good health','Good health','Fair health']].sum(axis=1)\n",
    "\n",
    "\n",
    "df_demg['Population in Bad Health']=df_demg[['Bad health', 'Very bad health']].sum(axis=1)\n",
    "\n",
    "\n",
    "health_ftrs=['Population in Good Health','Population in Bad Health']\n",
    "\n",
    "df_demg['Mixed/Black/others']=df_demg[['Mixed/multiple ethnic groups',\\\n",
    "                                       'Black/African/Caribbean/Black British',\\\n",
    "                                       'Other ethnic group']].sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ethnic_ftrs=['White','Asian/Asian British','Mixed/Black/others']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "df_demg['2 or more cars or vans in household']=df_demg[['2 cars or vans in household',\\\n",
    "                                                        '3 cars or vans in household',\\\n",
    "                                                        '4 or more cars or vans in household']].sum(axis=1)\n",
    "\n",
    "vehicle_ftrs=['No cars or vans in household', '1 car or van in household',\\\n",
    "                  '2 or more cars or vans in household']\n",
    "\n",
    "\n",
    "\n",
    "all_ftrs_sbset=[household_occupancy_ftrs,age_ftrs,deprivation_ftrs,econominc_activity_ftrs,health_ftrs,ethnic_ftrs,\\\n",
    "                vehicle_ftrs]\n",
    "\n",
    "# Get proportion of all Census features\n",
    "for cols in all_ftrs_sbset:\n",
    "    \n",
    "    df_demg[cols]=get_proportion(df_demg,cols)\n",
    "    \n",
    "    \n",
    "\n",
    "df_demg=df_demg[[item for sublist in all_ftrs_sbset for item in sublist]+\\\n",
    "                people_density_ftrs+['counter']+['geometry','urban_rural']+['2011 output area']].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the demographic data for counter sites Natural England vs North Downs Way vs River Canal Trust and compute average values of Census variables for each counter sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demg_ne=df_demg[df_demg['counter'].isin(list(counter_ne['counter'].values))].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_demg_nd=df_demg[df_demg['counter'].isin(list(counter_nd['counter'].values))].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_demg_cr=df_demg[df_demg['counter'].isin(list(counter_cr['counter'].values))].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define baseline population for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Socio-economic demographic features\n",
    "\n",
    "ftrs_to_keep_pop=[item for sublist in all_ftrs_sbset for item in sublist]+people_density_ftrs\n",
    "\n",
    "\n",
    "\n",
    "# For regression analysis we need to define baseline population- \n",
    "# against which the regr coefs can be compared\n",
    "\n",
    "baseline_pop=['1-2 people in household', 'Age group 65+', 'Household is not deprived in any dimension',\\\n",
    "'Economically Inactive' ,'Population in Good Health', 'White', '1 car or van in household'] \n",
    "\n",
    "\n",
    "ftrs_to_keep_pop=[x for x in ftrs_to_keep_pop if x not in baseline_pop]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile demographic features from non-baseline population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average proportion of Census variables for all counter sites excluding baseline population\n",
    "\n",
    "\n",
    "# Natural England Counters\n",
    "df_demg_ne[ftrs_to_keep_pop]=df_demg_ne[ftrs_to_keep_pop].astype(float)\n",
    "\n",
    "df_demg_ne=df_demg_ne.groupby('counter')[ftrs_to_keep_pop].mean().reset_index()\n",
    "\n",
    "# Merge it with buffer zone areas for each site\n",
    "df_demg_ne=df_demg_ne.merge(area_sites_oa,on=['counter'],how='inner')\n",
    "\n",
    "# normalise the census features same units as pois\n",
    "\n",
    "num_cols=[x for x in ftrs_to_keep_pop if x not in people_density_ftrs]\n",
    "\n",
    "#df_demg_ne[num_cols]=df_demg_ne[num_cols].div(df_demg_ne['area_sq_km'],axis=0)\n",
    "\n",
    "del df_demg_ne['area_sq_km']\n",
    "\n",
    "\n",
    "# North Downs Way Counters\n",
    "df_demg_nd[ftrs_to_keep_pop]=df_demg_nd[ftrs_to_keep_pop].astype(float)\n",
    "\n",
    "df_demg_nd=df_demg_nd.groupby('counter')[ftrs_to_keep_pop].mean().reset_index()\n",
    "\n",
    "# Merge it with buffer zone areas for each site\n",
    "df_demg_nd=df_demg_nd.merge(area_sites_oa,on=['counter'],how='inner')\n",
    "\n",
    "# normalise the census features same units as pois\n",
    "\n",
    "#df_demg_nd[num_cols]=df_demg_nd[num_cols].div(df_demg_nd['area_sq_km'],axis=0)\n",
    "\n",
    "del df_demg_nd['area_sq_km']\n",
    "\n",
    "\n",
    "# CRT Counters\n",
    "df_demg_cr[ftrs_to_keep_pop]=df_demg_cr[ftrs_to_keep_pop].astype(float)\n",
    "\n",
    "df_demg_cr=df_demg_cr.groupby('counter')[ftrs_to_keep_pop].mean().reset_index()\n",
    "\n",
    "# Merge it with buffer zone areas for each site\n",
    "df_demg_cr=df_demg_cr.merge(area_sites_oa,on=['counter'],how='inner')\n",
    "\n",
    "# normalise the census features same units as pois\n",
    "\n",
    "#df_demg_cr[num_cols]=df_demg_cr[num_cols].div(df_demg_cr['area_sq_km'],axis=0)\n",
    "\n",
    "del df_demg_cr['area_sq_km']\n",
    "\n",
    "\n",
    "all_sites_demographic=pd.concat([df_demg_ne[ftrs_to_keep_pop],df_demg_nd[ftrs_to_keep_pop],\\\n",
    "                                 df_demg_cr[ftrs_to_keep_pop]]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Analysis on Census Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create factor analysis object and perform factor analysis\n",
    "\n",
    "df_chsen=all_sites_demographic\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(df_chsen)\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "\n",
    "#Number of factors is equal to those with eigen values > 1\n",
    "numb_fctr=sum(i > 1 for i in list(ev))\n",
    "\n",
    "# re-run factor analysis with only factors whos eigenvector was > 1 in initial run \n",
    "fa = FactorAnalyzer(n_factors=numb_fctr)\n",
    "fa.fit(df_chsen)\n",
    "\n",
    "\n",
    "df_load=pd.DataFrame(fa.loadings_,columns=['Factor_'+str(x+1) for x in range(numb_fctr)]).\\\n",
    "set_index(df_chsen.columns)\n",
    "\n",
    "print(df_load[abs(df_load)>0.5].fillna('--'))\n",
    "\n",
    "\n",
    "print(fa.get_communalities())\n",
    "\n",
    "\n",
    "# 1. Sum of squared loadings (variance)\n",
    "# 2. Proportional variance\n",
    "# 3. Cumulative variance\n",
    "print(fa.get_factor_variance())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferring factor loadings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial correlations amongst areas with high:\n",
    "1. Proportion of deprived households, unemployed population,\n",
    "   proportion of population in bad health,\n",
    "2. Proportion of larger households, younger age population, Asian demographics\n",
    "3. Proportion of more densely populated areas, no cars or vans, with higher proportion of population Black/Mixed ethnic background,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_dat_all_sites=pd.concat([df_demg_ne[ftrs_to_keep_pop+['counter']],\\\n",
    "                                    df_demg_nd[ftrs_to_keep_pop+['counter']],\\\n",
    "                                    df_demg_cr[ftrs_to_keep_pop+['counter']]]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "demographic_dat_all_sites.to_pickle(data_folder+'socio_economic_data_all_sites.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Variance Inflation Factor to identify possible correlations between demographic and Points Of Interest features\n",
    "\n",
    "#The Variance Inflation Factor (VIF) is a measure of colinearity \n",
    "#among predictor variables within a multiple regression. It is \n",
    "#calculated by taking the the ratio of the variance of all a given model's\n",
    "#betas divide by the variane of a single beta if it were fit alone.\n",
    "\n",
    "https://quantifyinghealth.com/vif-threshold/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge demographic and POI features\n",
    "df_pois_demo_all_sites=df_pois_all_sites.merge(demographic_dat_all_sites,left_on=['site'],\\\n",
    "                                               right_on=['counter'],how='inner')\n",
    "\n",
    "df_pois_demo_all_sites=df_pois_demo_all_sites._get_numeric_data()\n",
    "\n",
    "df_chsen=df_pois_demo_all_sites\n",
    "\n",
    "# For each ftr, calculate VIF and save in dataframe\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_chsen.values, i) for \\\n",
    "                     i in range(df_chsen.shape[1])]\n",
    "vif[\"features\"] = df_chsen.columns\n",
    "print(vif)\n",
    "\n",
    "print('+'*100)\n",
    "\n",
    "#select only features with VIF score <= 2.5\n",
    "\n",
    "df_cens_remv_multi_coll=calculate_vif_(df_chsen._get_numeric_data(),\\\n",
    "                                       thresh=2.5)[0]\n",
    "\n",
    "# For each ftr, calculate VIF and save in dataframe\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_cens_remv_multi_coll.values, i) for \\\n",
    "                     i in range(df_cens_remv_multi_coll.shape[1])]\n",
    "vif[\"features\"] = df_cens_remv_multi_coll.columns\n",
    "print(vif)\n",
    "\n",
    "# select only low VIF score features\n",
    "low_vif_ftrs_cens=list(vif.features.values)\n",
    "\n",
    "\n",
    "# Joint Census ftrs and POIS\n",
    "sel_demo_pois_vrbls=low_vif_ftrs_cens\n",
    "\n",
    "# correlation matrix of varibales with low VIF Score\n",
    "get_corr_matrx(df_chsen[low_vif_ftrs_cens],0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Counter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter counter data for a subset of monitoring sites (where data quality is good enough based on preprocessing of counter data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter sites for which we have the people counter data (after pre-processing)\n",
    "\n",
    "# Natural England\n",
    "places_ne=[x.replace(\"  \",\" \").replace(\" \",\"_\") for x in df_count_ne.columns if x not in ['Date', 'Month']]\n",
    "# Only get coordinates for those sites\n",
    "counter_ne=counter_ne[counter_ne['counter'].isin(places_ne)].reset_index(drop=True)\n",
    "counter_ne['coordinates'] = list(zip(counter_ne.latitude, counter_ne.longitude))\n",
    "site_names_ne=list(counter_ne['counter'])\n",
    "# save sites with good data quality\n",
    "counter_ne.to_pickle(data_folder+'counter_ne.pkl')\n",
    "\n",
    "\n",
    "# North Downs Way\n",
    "places_nd=[x.replace(\"  \",\" \").replace(\" \",\"_\") for x in df_count_nd.columns if x not in ['Date', 'Month']]\n",
    "# Only get coordinates for those sites\n",
    "counter_nd=counter_nd[counter_nd['counter'].isin(places_nd)].reset_index(drop=True)\n",
    "counter_nd['coordinates'] = list(zip(counter_nd.latitude, counter_nd.longitude))\n",
    "site_names_nd=list(counter_nd['counter'])\n",
    "# save sites with good data quality\n",
    "counter_nd.to_pickle(data_folder+'counter_nd.pkl')\n",
    "\n",
    "\n",
    "# River and Canal Trust: No counter data available yet (17-02-2023)\n",
    "counter_cr.to_pickle(data_folder+'counter_cr.pkl')\n",
    "places_cr=df_demg_cr['counter'].unique().tolist()\n",
    "site_names_cr=places_cr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRAVA Metro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following steps are required to clean up the name of folders obtained from Strava\n",
    "\n",
    "file_names_ne=[x[0] for x in os.walk(strava_data_loc) if '_ped' in x[0]]\n",
    "\n",
    "for x in file_names_ne:\n",
    "    os.rename(x,x.replace('_1_edge_daily_2020-01-01-2022-11-30_ped',\"\"))\n",
    "    \n",
    "    \n",
    "file_names_nd=[x[0] for x in os.walk(val_strava_data_loc) if '_ped' in x[0]]\n",
    "\n",
    "for x in file_names_nd:\n",
    "    os.rename(x,x.replace('_1_edge_daily_2020-01-01-2022-11-30_ped',\"\"))\n",
    "    \n",
    "    \n",
    "file_names_nd=[x[0] for x in os.walk(canal_trust_strava_data_loc) if '_ped' in x[0]]\n",
    "\n",
    "for x in file_names_nd:\n",
    "    os.rename(x,x.replace('_1_edge_daily_2020-01-01-2022-11-30_ped',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Strava data\n",
    "\n",
    "strava_count_ne=prepare_strava(site_names_ne,strava_data_loc) \n",
    "\n",
    "strava_count_nd=prepare_strava(site_names_nd,val_strava_data_loc)\n",
    "\n",
    "strava_count_cr=prepare_strava(site_names_cr,canal_trust_strava_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strava_count_ne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of counter data and reshaping the data to merge with the Strava Metro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural England\n",
    "\n",
    "# data wrangling\n",
    "df_count_ne_strava=df_count_ne.copy()\n",
    "df_count_ne_strava.columns=[x.replace(\"  \",\" \").replace(\" \",\"_\") for x in df_count_ne_strava.columns]\n",
    "df_count_ne_strava=df_count_ne_strava.stack().reset_index()\n",
    "df_count_ne_strava.columns = ['Date', 'site', 'people_counter_data']\n",
    "df_count_ne_strava['Date']=df_count_ne_strava['Date'].dt.to_period('M').astype(\"string\")\n",
    "\n",
    "print('+'*200)\n",
    "\n",
    "# merge people counter and strava data \n",
    "df_count_ne_strava=df_count_ne_strava.merge(strava_count_ne,how='inner',left_on=['Date','site'],\\\n",
    "                                            right_on=['Date','site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# North Downs Way\n",
    "\n",
    "# data wrangling\n",
    "df_count_nd_strava=df_count_nd.copy()\n",
    "df_count_nd_strava.columns=[x.replace(\"  \",\" \").replace(\" \",\"_\") for x in df_count_nd_strava.columns]\n",
    "df_count_nd_strava=df_count_nd_strava.stack().reset_index()\n",
    "df_count_nd_strava.columns = ['Date', 'site', 'people_counter_data']\n",
    "df_count_nd_strava['Date']=df_count_nd_strava['Date'].dt.to_period('M').astype(\"string\")\n",
    "\n",
    "print('+'*200)\n",
    "\n",
    "# merge people counter and strava data \n",
    "df_count_nd_strava=df_count_nd_strava.merge(strava_count_nd,how='inner',left_on=['Date','site'],\\\n",
    "                                            right_on=['Date','site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canal River Trust\n",
    "\n",
    "df_count_cr_strava=strava_count_cr\n",
    "\n",
    "print('+'*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single data frame of strava and people counter data for all sites\n",
    "strava_dat_all_sites=pd.concat([df_count_ne_strava,df_count_nd_strava, df_count_cr_strava]).reset_index(drop=True)\n",
    "\n",
    "strava_dat_all_sites.to_pickle(data_folder+'strava_data_all_sites.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of correlations of counter data with Strava Metro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom palette\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=20, n=9, center=\"light\", as_cmap=True)\n",
    "\n",
    "# Compute corr matrix\n",
    "matrix = strava_dat_all_sites.set_index('Date').corr(method=\"pearson\")\n",
    "\n",
    "# plot the STRAVA metro data with the highest correlation with the Counter data\n",
    "matrix.sort_values(by='people_counter_data',ascending=False)['people_counter_data'][1:].plot(kind='barh',figsize=(10,7))\n",
    "plt.xlabel('Pearson correlation')\n",
    "\n",
    "# we hand-pick a feature with the highest correlation \n",
    "# with the NE counter feature: we choose total_trip_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Regression Model\n",
    "\n",
    "<a id='dest_5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural England: \n",
    "\n",
    "df_univ_ne=df_count_ne_strava[['Date','site','people_counter_data',chsen_ftr_strava]].copy()\n",
    "df_univ_ne=df_univ_ne.set_index('Date').sort_index()\n",
    "\n",
    "# Univariate regression model between people counter-Strava\n",
    "df = df_univ_ne\n",
    "fig = px.scatter(df, x=chsen_ftr_strava, y=\"people_counter_data\",\\\n",
    "                  color=\"site\",trendline=\"ols\")\n",
    "fig.show()\n",
    "\n",
    "results = px.get_trendline_results(fig)\n",
    "\n",
    "# Store univariate regression outputs\n",
    "site_values=results['site'].values\n",
    "\n",
    "str_regrn_ne=[]\n",
    "for sites in site_values:\n",
    "    df_site=df[df['site']==sites]\n",
    "    scaler = StandardScaler()\n",
    "    df_site[[\"people_counter_data\",chsen_ftr_strava]]=scaler.fit_transform(df_site[[\"people_counter_data\",chsen_ftr_strava]])\n",
    "    lm = pg.linear_regression(df_site[['people_counter_data']],df_site[chsen_ftr_strava])\n",
    "    lm['site']=sites\n",
    "    str_regrn_ne.append(lm)\n",
    "    \n",
    "str_regrn_ne=pd.concat(str_regrn_ne).reset_index(drop=True)\n",
    "\n",
    "str_regrn_ne[['r2','site']].drop_duplicates().set_index('site').sort_values(by='r2',ascending=False).\\\n",
    "plot(kind='barh',figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# North Downs Way\n",
    "\n",
    "df_univ_nd=df_count_nd_strava[['Date','site','people_counter_data',chsen_ftr_strava]].copy()\n",
    "df_univ_nd=df_univ_nd.set_index('Date').sort_index()\n",
    "\n",
    "# Univariate regression model between people counter-Strava\n",
    "df = df_univ_nd\n",
    "fig = px.scatter(df, x=chsen_ftr_strava, y=\"people_counter_data\",\\\n",
    "                  color=\"site\",trendline=\"ols\")\n",
    "fig.show()\n",
    "\n",
    "results = px.get_trendline_results(fig)\n",
    "\n",
    "# Store univariate regression outputs\n",
    "site_values=results['site'].values\n",
    "\n",
    "str_regrn_nd=[]\n",
    "for sites in site_values:\n",
    "    df_site=df[df['site']==sites]\n",
    "    scaler = StandardScaler()\n",
    "    df_site[[\"people_counter_data\",chsen_ftr_strava]]=scaler.fit_transform(df_site[[\"people_counter_data\",chsen_ftr_strava]])\n",
    "    lm = pg.linear_regression(df_site[['people_counter_data']],df_site[chsen_ftr_strava])\n",
    "    lm['site']=sites\n",
    "    str_regrn_nd.append(lm)\n",
    "    \n",
    "str_regrn_nd=pd.concat(str_regrn_nd).reset_index(drop=True)\n",
    "\n",
    "str_regrn_nd[['r2','site']].drop_duplicates().set_index('site').sort_values(by='r2',ascending=False).\\\n",
    "plot(kind='barh',figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_regrn_ne_nd=pd.concat([str_regrn_ne,str_regrn_nd])\n",
    "\n",
    "str_regrn_ne_nd=str_regrn_ne_nd[str_regrn_ne_nd['names'].isin(['people_counter_data'])]\n",
    "\n",
    "str_regrn_ne_nd=str_regrn_ne_nd[['names','coef','pval','site']]\n",
    "\n",
    "str_regrn_ne_nd=str_regrn_ne_nd[str_regrn_ne_nd['pval']<0.05]\n",
    "\n",
    "str_regrn_ne_nd_countr=str_regrn_ne_nd[str_regrn_ne_nd['names']=='people_counter_data']\n",
    "\n",
    "\n",
    "str_regrn_ne_nd_countr[['coef','site']].drop_duplicates().set_index('site').sort_values(by='coef',ascending=False).\\\n",
    "plot(kind='barh',figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# River and Canal Trust: No counter data available\n",
    "\n",
    "df_univ_cr=df_count_cr_strava[['Date','site',chsen_ftr_strava]].copy()\n",
    "\n",
    "\n",
    "df_univ_cr=df_univ_cr.set_index('Date').sort_index()\n",
    "\n",
    "\n",
    "df_univ_cr=df_univ_cr[['site',chsen_ftr_strava]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge static and dynamic features\n",
    "\n",
    "<a id='dest_6'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Merge OSM data with counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dynamic features with static (spatial) features: Natural England\n",
    "\n",
    "df_univ_ne=df_univ_ne.reset_index().merge(df_pois_all_sites,on=['site'],how='inner').\\\n",
    "set_index('Date').sort_index()\n",
    "\n",
    "df_univ_ne=df_univ_ne.reset_index()\n",
    "\n",
    "df_univ_ne=df_univ_ne.sort_values(['Date', 'site'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dynamic features with static (spatial) features: North Downs\n",
    "\n",
    "df_univ_nd=df_univ_nd.reset_index().merge(df_pois_all_sites,on=['site'],how='inner').\\\n",
    "set_index('Date').sort_index()\n",
    "\n",
    "df_univ_nd=df_univ_nd.reset_index()\n",
    "\n",
    "df_univ_nd=df_univ_nd.sort_values(['Date', 'site'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dynamic features with static (spatial) features: Canal and River Trust\n",
    "\n",
    "df_univ_cr=df_univ_cr.reset_index().merge(df_pois_all_sites,on=['site'],how='inner').\\\n",
    "set_index('Date').sort_index()\n",
    "\n",
    "df_univ_cr=df_univ_cr.reset_index()\n",
    "\n",
    "df_univ_cr=df_univ_cr.sort_values(['Date', 'site'],ascending=[True, True])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge Weather data with counter data\n",
    "\n",
    "Filter weather data for people counter sites\n",
    "\n",
    "https://meteostat.net/en/blog/obtain-weather-data-any-location-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df=pd.read_pickle(data_folder+'weather_df.pkl')\n",
    "\n",
    "weather_df['Date']=weather_df['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_ne['Date']=df_univ_ne['Date'].astype(str)\n",
    "\n",
    "df_univ_ne=df_univ_ne.copy().merge(weather_df,on=['Date','site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_ne.isna().sum(axis=0).sum(),df_univ_ne['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_nd['Date']=df_univ_nd['Date'].astype(str)\n",
    "\n",
    "df_univ_nd=df_univ_nd.copy().merge(weather_df,on=['Date','site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_nd.isna().sum(axis=0).sum(),df_univ_nd['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_cr['Date']=df_univ_cr['Date'].astype(str)\n",
    "\n",
    "df_univ_cr=df_univ_cr.copy().merge(weather_df,on=['Date','site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_cr.isna().sum(axis=0).sum(),df_univ_cr['site'].unique().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge Demographic data with counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demg_ne.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "df_demg_nd.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "df_demg_cr.rename(columns={'counter':'site'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_ne=df_univ_ne.merge(df_demg_ne,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_ne.isna().sum(axis=0).sum(),df_univ_ne['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_nd=df_univ_nd.merge(df_demg_nd,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_nd.isna().sum(axis=0).sum(),df_univ_nd['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univ_cr=df_univ_cr.merge(df_demg_cr,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_cr.isna().sum(axis=0).sum(),df_univ_cr['site'].unique().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge green infrastructure data with counter data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required variables\n",
    "\n",
    "df_grn_inf=pd.read_pickle(data_folder+'green_blue_prow_ftrs.pkl')\n",
    "\n",
    "df_grn_inf.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "\n",
    "sel_green_ftrs=['site','accessible_green_space_area','waterside_length_km','PROW_Total_length_km']\n",
    "\n",
    "df_grn_inf=df_grn_inf[sel_green_ftrs]\n",
    "\n",
    "\n",
    "\n",
    "df_grn_inf=df_grn_inf.set_index('site')\n",
    "\n",
    "\n",
    "\n",
    "green_infrastrcur_ftrs=list(df_grn_inf.columns)\n",
    "\n",
    "df_grn_inf=df_grn_inf.reset_index()\n",
    "\n",
    "#df_grn_inf=df_grn_inf.merge(area_sites_oa.rename(columns={'counter':'site'}),on=['site'],how='inner')\n",
    "\n",
    "#df_grn_inf['accessible_green_space_area']=df_grn_inf['accessible_green_space_area'].div(df_grn_inf['area_sq_km'])\n",
    "\n",
    "#df_grn_inf['waterside_length_km']=df_grn_inf['waterside_length_km'].div(np.sqrt(df_grn_inf['area_sq_km']))\n",
    "\n",
    "#df_grn_inf['PROW_Total_length_km']=df_grn_inf['PROW_Total_length_km'].div(np.sqrt(df_grn_inf['area_sq_km']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE GREEN INFRASTRUCTURE FEATURES on counter data: Natural England \n",
    "\n",
    "df_univ_ne=df_univ_ne.merge(df_grn_inf,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_ne.isna().sum(axis=0).sum(),df_univ_ne['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE GREEN INFRASTRUCTURE FEATURES on counter data: North Downs Way \n",
    "\n",
    "\n",
    "df_univ_nd=df_univ_nd.merge(df_grn_inf,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_nd.isna().sum(axis=0).sum(),df_univ_nd['site'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE GREEN INFRASTRUCTURE FEATURES on counter data: canal and river trust \n",
    "\n",
    "\n",
    "df_univ_cr=df_univ_cr.merge(df_grn_inf,on=['site'],how='inner')\n",
    "\n",
    "print('Number of null values {} and number of unique counter sites is {}'.\\\n",
    "      format(df_univ_cr.isna().sum(axis=0).sum(),df_univ_cr['site'].unique().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Merge season information with counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce seasons\n",
    "        \n",
    "df_univ_ne['season']=df_univ_ne['Date'].apply(lambda x: x.split('-')[1]).apply(lambda x : get_season(x))\n",
    "\n",
    "\n",
    "df_univ_nd['season']=df_univ_nd['Date'].apply(lambda x: x.split('-')[1]).apply(lambda x : get_season(x))\n",
    "\n",
    "\n",
    "df_univ_cr['season']=df_univ_cr['Date'].apply(lambda x: x.split('-')[1]).apply(lambda x : get_season(x))\n",
    "\n",
    "\n",
    "df_univ_ne=pd.get_dummies(df_univ_ne,columns=['season'])\n",
    "\n",
    "df_univ_nd=pd.get_dummies(df_univ_nd,columns=['season'])\n",
    "\n",
    "df_univ_cr=pd.get_dummies(df_univ_cr,columns=['season'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Merge land habitat and land type information with counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data: each site is classified into habitat type and land type class\n",
    "\n",
    "land_habitat_df=pd.read_pickle(habitat_cluster_file)\n",
    "\n",
    "del land_habitat_df['geometry']\n",
    "\n",
    "land_habitat_df.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "land_habitat_df.rename(columns={'labels':'habitat_type_labels'},inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "land_cluster_df=pd.read_pickle(land_cluster_file)\n",
    "\n",
    "del land_cluster_df['geometry']\n",
    "\n",
    "land_cluster_df.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "land_cluster_df.rename(columns={'labels':'land_type_labels'},inplace=True)\n",
    "\n",
    "print(list(land_cluster_df['land_type_labels'].unique()))\n",
    "\n",
    "print(list(land_habitat_df['habitat_type_labels'].unique()))\n",
    "\n",
    "\n",
    "\n",
    "df_univ_ne=df_univ_ne.merge(land_cluster_df[['site','land_type_labels']],on=['site'],how='inner')\n",
    "df_univ_ne=df_univ_ne.merge(land_habitat_df[['site','habitat_type_labels']],on=['site'],how='inner')\n",
    "\n",
    "df_univ_nd=df_univ_nd.merge(land_cluster_df[['site','land_type_labels']],on=['site'],how='inner')\n",
    "df_univ_nd=df_univ_nd.merge(land_habitat_df[['site','habitat_type_labels']],on=['site'],how='inner')\n",
    "\n",
    "df_univ_cr=df_univ_cr.merge(land_cluster_df[['site','land_type_labels']],on=['site'],how='inner')\n",
    "df_univ_cr=df_univ_cr.merge(land_habitat_df[['site','habitat_type_labels']],on=['site'],how='inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Merge Dog ownership data with counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df_dog_ownrshp=pd.read_pickle(dog_ownership)\n",
    "\n",
    "df_dog_ownrshp.rename(columns={'counter':'site'},inplace=True)\n",
    "\n",
    "df_univ_ne=df_univ_ne.merge(df_dog_ownrshp,on=['site'],how='left').fillna(0)\n",
    "\n",
    "df_univ_nd=df_univ_nd.merge(df_dog_ownrshp,on=['site'],how='left').fillna(0)\n",
    "\n",
    "df_univ_cr=df_univ_cr.merge(df_dog_ownrshp,on=['site'],how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demog_ftrs=[x for x in list(all_sites_demographic.select_dtypes(include=[np.number]).columns.values)]\n",
    "\n",
    "#print(demog_ftrs)\n",
    "\n",
    "ftrs_to_keep=list(set(df_univ_ne.columns).intersection(df_univ_nd.columns))\n",
    "\n",
    "ftrs_to_keep=list(set(ftrs_to_keep).intersection(df_univ_cr.columns))\n",
    "\n",
    "print(sorted(ftrs_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data for all the sites\n",
    "df_sites_ne_nd_cr=pd.concat([df_univ_ne[ftrs_to_keep+[target]],df_univ_nd[ftrs_to_keep+[target]],\\\n",
    "                             df_univ_cr[ftrs_to_keep]],axis=0).reset_index(drop=True)\n",
    "\n",
    "df_sites_ne_nd_cr.to_pickle(data_folder+'complete_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sites_ne_nd_cr.dropna().groupby('Date')['site'].count().plot(style='-o')\n",
    "plt.ylabel('Number of monitoring sites with training data available')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "req_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 14:59:37) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "73dd042dec22895802a5cf4c230cd0d0aa33a4e312107f26490806e8c532eb8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
