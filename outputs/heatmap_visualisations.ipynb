{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model_config import *\n",
    "from model_packages import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile with buffer zone geometries for each site \n",
    "accessibility= gpd.read_file('./data/accessibility.shp').to_crs(crs_deg)\n",
    "accessibility['latitude']=accessibility['geometry'].centroid.y\n",
    "accessibility['longitude']=accessibility['geometry'].centroid.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data with UK regions \n",
    "regions= gpd.read_file('./data/NUTS_RG_20M_2021_4326.geojson')\n",
    "# select desired geography level i.e. North East, North West etc\n",
    "regions=regions.loc[(regions['CNTR_CODE']=='UK')&(regions['LEVL_CODE']==1)]\n",
    "# create data frame with geometry of region related to each counter location\n",
    "regions_geom=gpd.sjoin(left_df=accessibility, right_df=regions[['geometry', 'NUTS_NAME']], how='right')\n",
    "regions_geom=regions_geom.drop(columns=['index_left'])\n",
    "\n",
    "# spatially join counter locations to UK region but keep geometry of buffer zones\n",
    "points_geom = gpd.sjoin(left_df=accessibility, right_df=regions[['geometry', 'NUTS_NAME']], how='left')\n",
    "# Single data point (Canal Side) incorrectly assigned to Wales region, reassign point to North West \n",
    "points_geom.NUTS_NAME= np.where(points_geom.NUTS_NAME =='Wales', 'North West (England)', points_geom.NUTS_NAME)\n",
    "points_geom=points_geom.drop(columns=['index_right'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Final Blended Model Heatmaps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of predictions from final model. Due to segmentation of data for cross validation predictions on training data set and validation data set are visualised together in order to visualise a complete temporal profile for each counter location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data of final blended model prediction on train and validation set\n",
    "pred_on_train= pd.read_pickle(data_folder+'pred_on_train_data.pkl')\n",
    "pred_on_val= pd.read_pickle(data_folder+'pred_on_val_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate training and validation predictions\n",
    "train_val_df= pd.concat([pred_on_train, pred_on_val], ignore_index=True, join='outer')\n",
    "\n",
    "# create subset of points_geom with only sites in train and val, this is used for plotting later\n",
    "train_sites= train_val_df.merge(points_geom, left_on='site', right_on='counter', how= 'inner')\n",
    "\n",
    "# assign season to each data point\n",
    "train_val_df['season']=train_val_df['Date'].apply(lambda x: x.split('-')[1]).\\\n",
    "apply(lambda x : get_season(x))\n",
    "\n",
    "# create year column\n",
    "train_val_df['year']= pd.to_datetime(train_val_df['Date']).dt.year\n",
    "train_val_df= train_val_df.merge(accessibility,left_on=['site'],right_on='counter',how='outer')\n",
    "\n",
    "# generate mean for each site per year and season\n",
    "train_val_df= train_val_df.groupby(['site','year', 'season'], sort=False).mean().reset_index()\n",
    "\n",
    "# add error column \n",
    "train_val_df['Error']= (train_val_df['people_counter_data']-train_val_df['prediction_label'])\n",
    "train_val_df['Strava Error']= (train_val_df['people_counter_data']-train_val_df['total_trip_count'])\n",
    "\n",
    "# wrangling for plotting purposes\n",
    "train_val_df['year']= train_val_df['year'].astype(int)\n",
    "train_val_df.season= train_val_df.season.astype('str').str.capitalize()\n",
    "train_val_df= train_val_df.rename(columns={'total_trip_count':'Strava Trip Count', 'people_counter_data': 'People Counter Data', 'prediction_label': 'Predicted Count'})\n",
    "# train_val_df= train_val_df.drop(columns=['Mean_dog_occupancy', 'waterside_length_km', 'land_type_labels_urban_and_rural_setings','habitat_type_labels_Grass_wood_bareground_coast',\t'tourism_camp_site', 'tourism_guest_house', 'highway_bus_stop', 'tourism_attraction', 'amenity_pub', 'amenity_beer_garden', 'amenity_bus_station', 'amenity_food_court', 'amenity_shelter', 'Asian/Asian British', '2 or more cars or vans in household', 'Density (number of persons per sq_km)', 'tavg', 'area'])\n",
    "\n",
    "\n",
    "# create df with regions\n",
    "train_val_df_regions=train_val_df.merge(points_geom, how='inner', left_on='site', right_on='counter')\n",
    "# group by region and sum\n",
    "train_val_df_regions= train_val_df_regions.groupby(['NUTS_NAME', 'year', 'season']).mean().reset_index()\n",
    "# merge again to regain geometry\n",
    "train_val_df_regions= train_val_df_regions.merge(regions, how='inner', on='NUTS_NAME')\n",
    "# convert to geodataframe\n",
    "train_val_df_regions=gpd.GeoDataFrame(train_val_df_regions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting for density maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['People Counter Data', 'Predicted Count', 'Error', 'Strava Trip Count', 'Strava Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_density_map(train_val_df, cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sites Coloured by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of sites coloured by region\n",
    "\n",
    "# convert to GeoDataFrame and change CRS\n",
    "train_sites =gpd.GeoDataFrame(train_sites).to_crs('3857')\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "train_sites.plot(\n",
    "    # Colour by region label\n",
    "    column='NUTS_NAME',\n",
    "    # Consider label as categorical\n",
    "    categorical=True,\n",
    "    # Include legend\n",
    "    legend=True,\n",
    "    # Draw on axis `ax`\n",
    "    ax=ax,\n",
    "    # Use circle as marker\n",
    "    marker=\"o\",\n",
    "    # colours for markers\n",
    "    cmap='tab10',\n",
    "    # legend outside the map\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.62, 1)},\n",
    ")\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.CartoDB.VoyagerNoLabels,\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_title('People counter sites coloured by region')\n",
    "ax.set_axis_off()\n",
    "f.tight_layout()\n",
    "# save figure to images folder\n",
    "# pathlib.Path(f\"./images/\").mkdir(parents=True, exist_ok=True)\n",
    "# f.savefig(f\"./images/train_sites_regions.png\", format= 'png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sites couloured by region blog visualisation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "regions.to_crs(crs_mtr).plot(ax=ax, facecolor= 'none', edgecolor='black', linewidth=1.2)\n",
    "\n",
    "markers=[\n",
    " 'o',\n",
    " 'v',\n",
    " 'd',\n",
    " \"P\",\n",
    " 's',\n",
    " \"X\",\n",
    " '*',\n",
    " 'h',\n",
    "]\n",
    "colours= {\n",
    "    'blue':    '#377eb8', \n",
    "    'orange':  '#ff7f00',\n",
    "    'green':   '#4daf4a',\n",
    "    'pink':    '#f781bf',\n",
    "    'brown':   '#a65628',\n",
    "    'purple':  '#984ea3',\n",
    "    'gray':    '#999999',\n",
    "    'red':     '#e41a1c',\n",
    "    'yellow':  '#dede00'\n",
    "} \n",
    "\n",
    "t= gpd.GeoDataFrame(train_sites).to_crs(crs_mtr)\n",
    "t.geometry= t.geometry.centroid\n",
    "margin = 490000\n",
    "ax.set_xlim(t.bounds.minx.min()-40000, t.bounds.maxx.max() + margin)\n",
    "ax.set_ylim(t.bounds.miny.min()-40000, t.bounds.maxy.max()+100000)\n",
    "t=anonymise_coordinates(t, 5000)\n",
    "groups=t[t['NUTS_NAME'] != 'London']\n",
    "groups= groups.groupby('NUTS_NAME')\n",
    "\n",
    "for (name, group), marker, colours in zip(groups, cycle(markers), cycle(colours)):\n",
    "    ax.plot(group.longitude, group.latitude,marker=marker, color=colours,  label=(name+f' (number of sites: {group.site.unique().shape[0]})'), linestyle='', markersize=6)\n",
    "    ax.legend(loc='upper right', fontsize=12, frameon=1, facecolor='white')#bbox_to_anchor=(2.55,1)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "contextily.add_basemap(ax,crs= crs_mtr,source=contextily.providers.Esri.WorldGrayCanvas, zoom=8)\n",
    "# Add padding between subplot titles and plot\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.show();\n",
    "\n",
    "# pathlib.Path(f\"./outputs/\").mkdir(parents=True, exist_ok=True)\n",
    "# fig.savefig(f\"./outputs/sites_x_region.png\", format= 'png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chloropleth visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_chlorpleth_map(train_val_df_regions, cols, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data for estimations and prediction on unseen sites\n",
    "\n",
    "# load CRT predictions\n",
    "estimation_trained_model= pd.read_pickle('./data/estimation_trained_model.pkl')\n",
    "estimation_trained_model= estimation_trained_model.rename(columns={'prediction_label':'Canals & Rivers Trust Prediction'})\n",
    "# add season to each data point\n",
    "estimation_trained_model['season']=estimation_trained_model['Date'].apply(lambda x: x.split('-')[1]).\\\n",
    "apply(lambda x : get_season(x))\n",
    "# add year to each data point\n",
    "estimation_trained_model['year']= pd.to_datetime(estimation_trained_model['Date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_trained_model= pd.read_pickle(data_folder+'prediction_trained_model.pkl')\n",
    "\n",
    "# add season to each data point\n",
    "prediction_trained_model['season']=prediction_trained_model['Date'].apply(lambda x: x.split('-')[1]).\\\n",
    "apply(lambda x : get_season(x))\n",
    "\n",
    "# add year to each data point\n",
    "prediction_trained_model['year']= pd.to_datetime(prediction_trained_model['Date']).dt.year\n",
    "\n",
    "# remove predcition label as we only want to visualise predcitions made on unsens sites \n",
    "# prediction_trained_model['prediction_label']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df= pd.concat([prediction_trained_model,estimation_trained_model], ignore_index=True, join='outer' )\n",
    "models_df= models_df.merge(accessibility,left_on=['site'],right_on='counter',how='outer')\n",
    "models_df= models_df.merge(points_geom, how='inner', left_on='site', right_on='counter')\n",
    "\n",
    "models_df= models_df.groupby(['NUTS_NAME','year', 'season']).mean().reset_index()\n",
    "models_df=models_df.merge(regions[['NUTS_NAME','geometry']], how='inner', on='NUTS_NAME')\n",
    "models_df['year']= models_df['year'].astype(int)\n",
    "models_df.season= models_df.season.astype('str').str.capitalize()\n",
    "modles_df= models_df.rename(columns={'total_trip_count':'Strava Trip Count', 'people_counter_data': 'People Counter Data', 'prediction_label': 'Predicted Count'}, inplace=True)\n",
    "# # models_df.NUTS_NAME= np.where(models_df.NUTS_NAME =='Wales', 'North West (England)', models_df.NUTS_NAME)\n",
    "\n",
    "models_df=gpd.GeoDataFrame(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional chloropleth maps for the estimation on unseen sites\n",
    "create_chlorpleth_map(models_df, ['Canals & Rivers Trust Prediction'], True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series visualisation of training and validation data and predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data frames to have all predictions in one \n",
    "ts_df= pd.concat([pred_on_train, pred_on_val], ignore_index=True, join='outer')\n",
    "# merge with points_geom to get regions\n",
    "ts_df=ts_df.merge(points_geom, how='inner', left_on='site', right_on='counter')\n",
    "# columns to keep\n",
    "keepers= ['Date', 'people_counter_data', 'prediction_label', 'NUTS_NAME', 'site']\n",
    "\n",
    "# copy data frame for plotting sites map\n",
    "ts_df_geo=ts_df.copy()\n",
    "\n",
    "# drop unneeded columns\n",
    "ts_df= ts_df[ts_df.columns.intersection(keepers)]\n",
    "ts_df.people_counter_data=ts_df.people_counter_data.astype('float32')\n",
    "\n",
    "\n",
    "# get mean value from all sites in a region\n",
    "ts_df= ts_df.groupby(['Date', 'NUTS_NAME']).mean().reset_index()\n",
    "# get error between predicted and actual data for each region\n",
    "ts_df['error']= (ts_df['people_counter_data']-ts_df['prediction_label'])\n",
    "ts_df=ts_df.set_index(pd.to_datetime(ts_df.Date), drop=True)\n",
    "ts_df=ts_df.drop('Date', axis=1)\n",
    "ts_df.head()\n",
    "# group by region\n",
    "ts_df= ts_df.groupby('NUTS_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table figure for count of sites in each region\n",
    "# group by region\n",
    "\n",
    "\n",
    "site_region_count=ts_df_geo.groupby(['NUTS_NAME'])\n",
    "# creat count column\n",
    "site_region_count=pd.DataFrame(site_region_count['site'].nunique()).reset_index()\n",
    "# rename for visualisation\n",
    "site_region_count= site_region_count.rename(columns={'NUTS_NAME': 'Region', 'site':'Number of Sites'})\n",
    "\n",
    "# create table\n",
    "fig= ff .create_table(site_region_count)\n",
    "fig.update_layout(autosize=False,\n",
    "    width=350,\n",
    "    height=200,)\n",
    "fig.show()\n",
    "\n",
    "# pathlib.Path(f\"./images/\").mkdir(parents=True, exist_ok=True)\n",
    "# fig.write_image(\"./images/train_site_count_table.png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib \n",
    "# Define colorblind-friendly color palette\n",
    "color_palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "# Define figure size and subplots layout\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,8), sharey=True, sharex=True)\n",
    "\n",
    "# Set font size for all text elements\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Loop through groups in dataframe\n",
    "for (key, ax) in zip(ts_df.groups.keys(), axes.flatten()):\n",
    "    # Set colorblind-friendly line style and color cycle\n",
    "    cycler = plt.cycler(linestyle=['-.', '-', '--'], color=color_palette[1:4])\n",
    "    ax.set_prop_cycle(cycler)\n",
    "    # Plot predicted and actual people count data\n",
    "    ts_df.get_group(key).plot(ax=ax, y=['prediction_label', 'people_counter_data'], grid=False, ylim=(-10, 500))\n",
    "    # Set plot title and font size\n",
    "    ax.set_title(key, fontsize=16, fontweight='bold')\n",
    "    # Set y-axis ticks and font size\n",
    "    ax.set_yticks([0, 100, 200, 300, 400, 500])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    # Set legend labels, title, and font size\n",
    "    ax.legend(['Predicted Count', 'Actual Count'], fontsize=12)\n",
    "    # Remove x-axis label\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "# Add main plot title\n",
    "fig.suptitle(\"Model estimation performs well in South East, South West and Yorkshire and the Humber\", fontsize=18, fontweight='bold')\n",
    "# Add padding between subplot titles and plot\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n",
    "# Make plot responsive for website viewing\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.1, hspace=0.2)\n",
    "\n",
    "pathlib.Path(f\"./outputs/\").mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(f\"./outputs/predict_vs_actual_ts_comparison.png\", format= 'png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot of time series for predicted and actual people count for each region\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12,8), sharey=True, sharex=True)\n",
    "\n",
    "# Set font size for all text elements\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# loop through groups in data frame\n",
    "for (key, ax) in zip(ts_df.groups.keys(), axes.flatten()):\n",
    "    cycler = plt.cycler(linestyle=['-', '-', '--'], color=['tab:red','tab:green', 'tab:red'])\n",
    "    ax.set_prop_cycle(cycler)\n",
    "    ts_df.get_group(key).plot(ax=ax, y= ['error'],grid=False) #ylim=(-10,500))\n",
    "    ax.set_title(key, fontsize=16, fontweight='bold')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    # ax.set_ylabel('People Count')\n",
    "    ax.legend(['Predicted Count Error'], fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "\n",
    "fig.suptitle(\"Estimation error is more significant for regions with fewer automated people counters\", fontsize=18, fontweight='bold')\n",
    "# Add padding between subplot titles and plot\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Make plot responsive for website viewing\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.1, hspace=0.2)\n",
    "\n",
    "pathlib.Path(f\"./outputs/\").mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(f\"./outputs/predict_vs_actual_error.png\", format= 'png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series visualisation including estimation for unseen sites from Canals & Rivers Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_sites= pd.read_pickle(data_folder+'crt_and_similar_sites.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_on_val.loc[pred_on_val.site.isin(similar_sites.counter)].site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data frames to have all predictions in one \n",
    "ts_df_crt= pd.concat([pred_on_train.loc[pred_on_train.site.isin(similar_sites.counter)], pred_on_val.loc[pred_on_val.site.isin(similar_sites.counter)], estimation_trained_model], ignore_index=True, join='outer')\n",
    "# merge with points_geom to get regions\n",
    "ts_df_crt=ts_df_crt.merge(points_geom, how='inner', left_on='site', right_on='counter')\n",
    "# columns to keep\n",
    "keepers= ['Date', 'people_counter_data', 'prediction_label', 'NUTS_NAME', 'Canals & Rivers Trust Prediction', 'site']\n",
    "\n",
    "# copy data frame for plotting sites map\n",
    "ts_df_crt_geo= ts_df_crt.copy()\n",
    "\n",
    "# drop unneeded columns\n",
    "ts_df_crt= ts_df_crt[ts_df_crt.columns.intersection(keepers)]\n",
    "ts_df_crt.people_counter_data=ts_df_crt.people_counter_data.astype('float32')\n",
    "cop=ts_df_crt.copy()\n",
    "# get mean value from all sites in a region\n",
    "ts_df_crt= ts_df_crt.groupby(['Date', 'NUTS_NAME']).mean().reset_index()\n",
    "ts_df_crt=ts_df_crt.set_index(pd.to_datetime(ts_df_crt.Date), drop=True)\n",
    "ts_df_crt=ts_df_crt.drop('Date', axis=1)\n",
    "\n",
    "# group by region\n",
    "ts_df_crt= ts_df_crt.groupby('NUTS_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop.loc[(cop['NUTS_NAME']== 'North West (England)')].site.unique() #& (cop['Date']=='2020-04')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot of time series for predicted and actual people count for each region including unseen data\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12,10), sharey=True)\n",
    "\n",
    "# loop through groups in data frame\n",
    "for (key, ax) in zip(ts_df_crt.groups.keys(), axes.flatten()):\n",
    "    cycler = plt.cycler(linestyle=['-.', '-', '--'], color=['tab:blue','tab:green', 'tab:red'])\n",
    "    ax.set_prop_cycle(cycler)\n",
    "    ts_df_crt.get_group(key).plot(ax=ax, grid=False, ylim=(-10,500))\n",
    "    ax.set_title(key)\n",
    "    ax.set_ylabel('People Count')\n",
    "    ax.legend(['Predicted Count', 'Actual Count', 'Estimated Canals & Rivers Trust'])\n",
    "\n",
    "\n",
    "fig.suptitle(\"Comparison of Predicted Count, Actual People Count and Estimated Count for Canals & Rivers Trust Locations\")\n",
    "fig.tight_layout()\n",
    "# pathlib.Path(f\"./outputs/\").mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(f\"./outputs/similar_sites_predict_vs_actual_vs_CRT_ts_comparison.png\", format= 'png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of single counter location to show buffer zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to GeoDataFrame and change CRS\n",
    "oneloc=ts_df_crt_geo.loc[ts_df_crt_geo['site']=='Banks_Lane']\n",
    "oneloc=gpd.GeoDataFrame(oneloc).to_crs('3857')\n",
    "oneloc['point']= oneloc.geometry.centroid\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "oneloc.plot(\n",
    "    # Colour by region label\n",
    "    column='NUTS_NAME',\n",
    "    # Consider label as categorical\n",
    "    categorical=True,\n",
    "    # Include legend\n",
    "    legend=False,\n",
    "    # Draw on axis `ax`\n",
    "    ax=ax,\n",
    "    # Use circle as marker\n",
    "    marker=\"o\",\n",
    "    markersize=1,\n",
    "    # colours for markers\n",
    "    facecolor='None',\n",
    "    edgecolor='lightcoral',\n",
    "    # Position legend outside the map\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.62, 1)},\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.OpenStreetMap.Mapnik,\n",
    ")\n",
    "oneloc.point.plot(ax=ax, facecolor='lightcoral')\n",
    "\n",
    "for x, y ,label in zip(oneloc.point.x, oneloc.point.y, oneloc.site):\n",
    "    ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\")\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "\n",
    "fig.show()\n",
    "# f.savefig(f\"./images/sites_regions_crt.png\", formt= 'png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Visualisation of sites by region including Canals & Rivers Trust Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of sites coloured by region\n",
    "\n",
    "# convert to GeoDataFrame and change CRS\n",
    "ts_df_crt_geo =gpd.GeoDataFrame(ts_df_crt_geo).to_crs('3857')\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "ts_df_crt_geo.plot(\n",
    "    # Colour by region label\n",
    "    column='NUTS_NAME',\n",
    "    # Consider label as categorical\n",
    "    categorical=True,\n",
    "    # Include legend\n",
    "    legend=True,\n",
    "    # Draw on axis `ax`\n",
    "    ax=ax,\n",
    "    # Use circle as marker\n",
    "    marker=\"o\",\n",
    "    # colours for markers\n",
    "    cmap='tab10',\n",
    "    # Position legend outside the map\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.62, 1)},\n",
    ")\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.CartoDB.VoyagerNoLabels,\n",
    ")\n",
    "# ax.set_title('People counter sites coloured by region including Canals & Rivers Trust')\n",
    "# Remove axes\n",
    "ax.set_axis_off()\n",
    "f.tight_layout()\n",
    "# f.savefig(f\"./images/sites_regions_crt.png\", format= 'png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Visualisation of sites most similar to Canals & Rivers Trust locations\n",
    " These are used for estimation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trng_sites= points_geom.loc[points_geom['counter'].isin(['Clevedon','Crickley_Hill_Country_Park',\n",
    "'Galley_Hall','Rocket_Post_Field','Ryhope_Dene','Saltburn','Teesdale_Way','Bluebell_Hill',\n",
    "'Hampton_Estate','Nickle_Farm_Chartham'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(10, 5))\n",
    "# Plot individual locations\n",
    "\n",
    "trng_sites.to_crs(crs_deg).plot(\n",
    "    # Colour by cluster label\n",
    "    column='NUTS_NAME',\n",
    "    #color=trng_sites['Color'],\n",
    "    cmap='tab10',\n",
    "    # Consider label as categorical\n",
    "    #categorical=False,\n",
    "    # Add 50% of transparency\n",
    "    alpha=0.95,\n",
    "    # Include legend\n",
    "    legend=True,\n",
    "    # Draw on axis `ax`\n",
    "    ax=ax,\n",
    "    # Use circle as marker\n",
    "    marker=\"o\",\n",
    "    # Position legend outside the map\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.45, 1)},\n",
    ")\n",
    "\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=trng_sites.to_crs(crs_deg).crs.to_string(),\n",
    "    source=contextily.providers.CartoDB.VoyagerNoLabels,\n",
    ")\n",
    "# Remove axes\n",
    "plt.title(label='Training Sites most similar to unseen locations')\n",
    "ax.set_axis_off()\n",
    "minx, miny, maxx, maxy = uk.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "# f.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Visualisation of Canals & Rivers Trust sites with similar locations in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_estimation=points_geom.loc[points_geom['counter'].isin(sim_sites)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(10, 5))\n",
    "# Plot individual locations\n",
    "\n",
    "sites_estimation.to_crs(crs_deg).plot(\n",
    "    # Colour by cluster label\n",
    "    column='NUTS_NAME',\n",
    "    #color=trng_sites['Color'],\n",
    "    cmap='tab10',\n",
    "    # Consider label as categorical\n",
    "    #categorical=False,\n",
    "    # Add 50% of transparency\n",
    "    alpha=0.95,\n",
    "    # Include legend\n",
    "    legend=True,\n",
    "    # Draw on axis `ax`\n",
    "    ax=ax,\n",
    "    # Use circle as marker\n",
    "    marker=\"o\",\n",
    "    # Position legend outside the map\n",
    "    legend_kwds={\"bbox_to_anchor\": (1.65, 1)},\n",
    ")\n",
    "\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    crs=sites_estimation.to_crs(crs_deg).crs.to_string(),\n",
    "    source=contextily.providers.CartoDB.VoyagerNoLabels,\n",
    ")\n",
    "# Remove axes\n",
    "plt.title(label='Most Similar sites in unseen data')\n",
    "    \n",
    "ax.set_axis_off()\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trng_estimation= pd.concat([sites_estimation, trng_sites])\n",
    "\n",
    "d= {'Number of Sites': trng_estimation.groupby(['NUTS_NAME']).counter.nunique()}\n",
    "trng_estimation= pd.DataFrame(d)\n",
    "trng_estimation= trng_estimation.reset_index()\n",
    "\n",
    "# create table\n",
    "fig= ff.create_table(trng_estimation)\n",
    "fig.update_layout(autosize=False,\n",
    "    width=350,\n",
    "    height=200,)\n",
    "fig.show()\n",
    "fig.write_image(\"./outputs/site_count_crt_table.png\", scale=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POIs Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demg=pd.read_pickle(census_locn_file)\n",
    "# Area of each buffer region around the counter sites.\n",
    "# Buffer zone is 5km radius around each site:pi*r^2: 78.5 sq km\n",
    "area_sites_oa=df_demg.groupby('counter')['area_sq_km'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data saved locally\n",
    "ne_pois_df=pd.read_pickle(data_folder+'ne_pois_df.pkl')\n",
    "\n",
    "# Read the data saved locally\n",
    "nd_pois_df=pd.read_pickle(data_folder+'dw_pois_df.pkl')\n",
    "\n",
    "# Read the data saved locally: river and canal trust\n",
    "cr_pois_df=pd.read_pickle(data_folder+'rvr_cnl_pois_df.pkl')\n",
    "\n",
    "\n",
    "# All pois across all sites\n",
    "df_pois_all_sites=pd.concat([ne_pois_df,nd_pois_df,cr_pois_df]).dropna(axis=1).reset_index(drop=True)\n",
    "\n",
    "# Merge it with buffer zone areas for each site\n",
    "df_pois_all_sites=df_pois_all_sites.merge(area_sites_oa.rename(columns={'counter':'site'}),on=['site'],how='outer')\n",
    "# create data frame of raw POI numbers \n",
    "raw_df= df_pois_all_sites.copy()\n",
    "\n",
    "num_cols=[x for x in df_pois_all_sites.columns if x not in ['area_sq_km','site']]\n",
    "\n",
    "# Density of pois--CJ: Is this better than raw numbers ?\n",
    "# Create data frame containing density of POIs by buffer zone area\n",
    "df_pois_all_sites[num_cols]=df_pois_all_sites[num_cols].div(df_pois_all_sites['area_sq_km'],axis=0)\n",
    "\n",
    "# del df_pois_all_sites['area_sq_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sum of all POIs for each site\n",
    "raw_df['All POIs']= raw_df.iloc[:, 0:17].sum(axis=1)\n",
    "# crreate sum of all POIs excluding pubs\n",
    "raw_df['POIs Excluding Pubs']= raw_df.drop('amenity_pub', axis=1).iloc[:, 0:16].sum(axis=1)\n",
    "# add urban_rural\n",
    "ur= pd.read_pickle(data_folder+'complete_dataset.pkl')\n",
    "raw_df=raw_df.merge(ur[['site', 'land_type_labels']], on='site', how='inner')\n",
    "\n",
    "\n",
    "# merge to get spatial information\n",
    "raw_df= raw_df.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "raw_df= raw_df.rename(columns={'tourism_attraction': 'Tourist Attractions', 'amenity_pub': 'Pubs', 'amenity_beer_garden': 'Beer Gardens','amenity_bus_station': 'Bus Stations', 'amenity_food_court': 'Food Courts','amenity_shelter':'Shelters'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots of raw POI numbers for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat data frame not containing sites from London. This helps with visualisations as London has a disporportionately high number of POIs\n",
    "# raw_df= raw_df.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "not_ldn= gpd.sjoin(left_df=gpd.GeoDataFrame(raw_df).to_crs(crs_mtr), right_df=regions_geom.to_crs(crs_mtr), how='right')\n",
    "\n",
    "ldn=['London']\n",
    "not_ldn= not_ldn[~not_ldn.NUTS_NAME.isin(ldn)]\n",
    "\n",
    "for i in ['All POIs', 'POIs Excluding Pubs', 'Pubs']:\n",
    "    regions = not_ldn.NUTS_NAME.unique()\n",
    "    colors = sns.color_palette('hls', len(regions))\n",
    "    palette = {region: color for region, color in zip(regions, colors)}\n",
    "    \n",
    "    fig, ax= plt.subplots(1,1)\n",
    "    sns.boxplot(ax= ax, x=i, y='NUTS_NAME', data= not_ldn.sort_values('NUTS_NAME'), palette=palette)\n",
    "    fig.suptitle(f'Boxplot of {i} for each UK region')\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    # pathlib.Path(f\"./images/POIs/\").mkdir(parents=True, exist_ok=True)\n",
    "    # fig.savefig(f'./images/POIs/boxplot_{i}.png')\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots of POI Density numbers for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_all_sites=df_pois_all_sites.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "not_ldn_density= gpd.sjoin(left_df=gpd.GeoDataFrame(df_pois_all_sites).to_crs(crs_mtr), right_df=regions_geom.to_crs(crs_mtr), how='left')\n",
    "ldn=['London']\n",
    "not_ldn_density= not_ldn_density[~not_ldn_density.NUTS_NAME.isin(ldn)]\n",
    "\n",
    "\n",
    "\n",
    "# not_ldn_density=not_ldn_density.merge(ur[['site', 'land_type_labels']], on='site', how='inner')\n",
    "# not_ldn_density=not_ldn_density.groupby('land_type_labels').mean().reset_index()\n",
    "\n",
    "\n",
    "# create sum of all POIs for each site\n",
    "not_ldn_density['All POIs']= not_ldn_density.iloc[:, 0:17].sum(axis=1)\n",
    "# crreate sum of all POIs excluding pubs\n",
    "not_ldn_density['POIs Excluding Pubs']= not_ldn_density.drop('amenity_pub', axis=1).iloc[:, 0:16].sum(axis=1)\n",
    "\n",
    "# df_pois_all_sites=df_pois_all_sites.merge(ur[['site', 'land_type_labels']], on='site', how='inner')\n",
    "# df_pois_all_sites=df_pois_all_sites.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "\n",
    "# not_ldn_density= gpd.GeoDataFrame(not_ldn_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='All POIs', y='land_type_labels', data= not_ldn.sort_values('All POIs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='POIs Excluding Pubs', y='land_type_labels', data= not_ldn.sort_values('POIs Excluding Pubs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Pubs', y='land_type_labels', data= not_ldn.sort_values('Pubs'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chloropleth Maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw POI numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe where raw POI numbers are totalled per region then divided by the total area of buffer zones within that region\n",
    "\n",
    "poi_bz= not_ldn.groupby('NUTS_NAME').sum().reset_index()\n",
    "poi_bz['NUTS_NAME']= np.where(poi_bz.NUTS_NAME =='Wales', 'North West (England)', poi_bz.NUTS_NAME) \n",
    "poi_bz['All POIs']= poi_bz['All POIs']/poi_bz['area_left']\n",
    "poi_bz['POIs Excluding Pubs']= poi_bz['POIs Excluding Pubs']/poi_bz['area_left']\n",
    "poi_bz['Pubs']= poi_bz['Pubs']/poi_bz['area_left']\n",
    "poi_bz= poi_bz.merge(regions_geom[['geometry', 'NUTS_NAME' ]], on= 'NUTS_NAME', how='inner')\n",
    "\n",
    "poi_bz=gpd.GeoDataFrame(poi_bz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot All POIs\n",
    "\n",
    "\n",
    "cols= ['All POIs', 'POIs Excluding Pubs', 'Pubs']\n",
    "\n",
    "for col in cols:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    data=poi_bz.to_crs('3857').plot(column=col, ax=ax, legend=True,cmap='OrRd',\n",
    "        legend_kwds={'label':f'{col}','orientation':'vertical'}\n",
    "    )\n",
    "\n",
    "    ts_df_crt_geo =gpd.GeoDataFrame(ts_df_crt_geo).to_crs('3857')\n",
    "\n",
    "    points=ts_df_crt_geo.plot(\n",
    "        # Colour by region label\n",
    "        column='NUTS_NAME',\n",
    "        # Consider label as categorical\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        label='People Counters',\n",
    "        # Draw on axis `ax`\n",
    "        ax=ax,\n",
    "        # Use circle as marker\n",
    "        marker=\"o\",\n",
    "        # marker size\n",
    "        markersize=1,\n",
    "        # colours for markers\n",
    "        color='slategrey',\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    contextily.add_basemap(\n",
    "        ax,\n",
    "            source=contextily.providers.CartoDB.Positron,\n",
    "    )\n",
    "\n",
    "    # add second legend for peopl counter locations\n",
    "    legend1 = ax.legend(handles=[\n",
    "                lines.Line2D(\n",
    "                    [],\n",
    "                    [],\n",
    "                    color=\"slategrey\",\n",
    "                    lw=0,\n",
    "                    marker=\"o\",\n",
    "                    markersize=5,\n",
    "                    label='People Counters',\n",
    "                    )], \n",
    "            scatterpoints=1, frameon=True,\n",
    "            labelspacing=1, loc='upper right', fontsize=8,  \n",
    "            title_fontsize=10,\n",
    "            labelcolor='black',\n",
    "            markerfirst=True,\n",
    "            labels=['People Counters']\n",
    "            )\n",
    "    fig.gca().add_artist(legend1)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax.set_title(f'{col} per area of all buffer zones in each region')\n",
    "\n",
    "    fig.show()\n",
    "    fig.tight_layout()\n",
    "    # fig.savefig(f'./images/POIs/total_buffer_area_{col}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe where POI densities are totalled per region then divided by the total area of buffer zones within that region\n",
    "\n",
    "poi_bz_density= not_ldn_density.groupby('NUTS_NAME').sum().reset_index()\n",
    "poi_bz_density['NUTS_NAME']= np.where(poi_bz_density.NUTS_NAME =='Wales', 'North West (England)', poi_bz_density.NUTS_NAME) \n",
    "poi_bz_density['All POIs']= poi_bz_density['All POIs']/poi_bz_density['area_left']\n",
    "poi_bz_density['POIs Excluding Pubs']= poi_bz_density['POIs Excluding Pubs']/poi_bz_density['area_left']\n",
    "poi_bz_density['amenity_pub']= poi_bz_density['amenity_pub']/poi_bz_density['area_left']\n",
    "poi_bz_density= poi_bz_density.merge(regions_geom[['geometry', 'NUTS_NAME' ]], on= 'NUTS_NAME', how='inner')\n",
    "\n",
    "poi_bz_density=gpd.GeoDataFrame(poi_bz_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot All POIs\n",
    "\n",
    "\n",
    "cols= ['All POIs', 'POIs Excluding Pubs', 'amenity_pub']\n",
    "\n",
    "for col in cols:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    data=poi_bz_density.to_crs('3857').plot(column=col, ax=ax, legend=True,cmap='OrRd',\n",
    "        legend_kwds={'label':f'Mean of {col}/km2 in Region','orientation':'vertical'}\n",
    "    )\n",
    "\n",
    "    ts_df_crt_geo =gpd.GeoDataFrame(ts_df_crt_geo).to_crs('3857')\n",
    "\n",
    "    points=ts_df_crt_geo.plot(\n",
    "        # Colour by region label\n",
    "        column='NUTS_NAME',\n",
    "        # Consider label as categorical\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        label='People Counters',\n",
    "        # Draw on axis `ax`\n",
    "        ax=ax,\n",
    "        # Use circle as marker\n",
    "        marker=\"o\",\n",
    "        # marker size\n",
    "        markersize=1,\n",
    "        # colours for markers\n",
    "        color='slategrey',\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    contextily.add_basemap(\n",
    "        ax,\n",
    "            source=contextily.providers.CartoDB.Positron,\n",
    "    )\n",
    "\n",
    "    # add second legend for peopl counter locations\n",
    "    legend1 = ax.legend(handles=[\n",
    "                lines.Line2D(\n",
    "                    [],\n",
    "                    [],\n",
    "                    color=\"slategrey\",\n",
    "                    lw=0,\n",
    "                    marker=\"o\",\n",
    "                    markersize=5,\n",
    "                    label='People Counters',\n",
    "                    )], \n",
    "            scatterpoints=1, frameon=True,\n",
    "            labelspacing=1, loc='upper right', fontsize=8,  \n",
    "            title_fontsize=10,\n",
    "            labelcolor='black',\n",
    "            markerfirst=True,\n",
    "            labels=['People Counters']\n",
    "            )\n",
    "    fig.gca().add_artist(legend1)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax.set_title(f'Mean of {col}/km2 by region')\n",
    "\n",
    "    fig.show()\n",
    "    fig.savefig(f'./images/POIs/pois_chloropleth_density_{col}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POIs visualisations for training data sites (i.e. not Canals & Rivers Trust locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur= pd.read_pickle(data_folder+'complete_dataset.pkl')\n",
    "\n",
    "# create not crt data\n",
    "not_crt=pd.concat([ne_pois_df,nd_pois_df]).dropna(axis=1).reset_index(drop=True)\n",
    "not_crt=not_crt.merge(area_sites_oa.rename(columns={'counter':'site'}),on=['site'],how='inner')\n",
    "\n",
    "# RAW\n",
    "raw_not_crt= not_crt.copy()\n",
    "raw_not_crt=raw_not_crt.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "\n",
    "# creat data frame not containing sites from London. This helps with visualisations as London has a disporportionately high number of POIs\n",
    "not_ldn_not_crt= gpd.sjoin(left_df=gpd.GeoDataFrame(raw_not_crt).to_crs(crs_mtr), right_df=points_geom.to_crs(crs_mtr), how='left')\n",
    "ldn=['London']\n",
    "not_ldn_not_crt= not_ldn_not_crt[~not_ldn_not_crt.NUTS_NAME.isin(ldn)]\n",
    "not_ldn_not_crt=not_ldn_not_crt.merge(ur[['site', 'land_type_labels']], on='site', how='inner')\n",
    "\n",
    "# create sum of all POIs for each site\n",
    "not_ldn_not_crt['All POIs']= not_ldn_not_crt.iloc[:, 0:17].sum(axis=1)\n",
    "# crreate sum of all POIs excluding pubs\n",
    "not_ldn_not_crt['POIs Excluding Pubs']= not_ldn_not_crt.drop('amenity_pub', axis=1).iloc[:, 0:16].sum(axis=1)\n",
    "\n",
    "\n",
    "# DENSITY\n",
    "num_cols=[x for x in not_crt.columns if x not in ['area_sq_km','site']]\n",
    "\n",
    "\n",
    "# Density of pois--CJ: Is this better than raw numbers ?\n",
    "not_crt[num_cols]=not_crt[num_cols].div(not_crt['area_sq_km'],axis=0)\n",
    "\n",
    "not_crt=not_crt.merge(accessibility, left_on='site', right_on='counter', how='inner')\n",
    "not_ldn_not_crt_density= gpd.sjoin(left_df=gpd.GeoDataFrame(not_crt).to_crs(crs_mtr), right_df=points_geom.to_crs(crs_mtr), how='left')\n",
    "ldn=['London']\n",
    "not_ldn_not_crt_density= not_ldn_not_crt_density[~not_ldn_not_crt_density.NUTS_NAME.isin(ldn)]\n",
    "\n",
    "\n",
    "\n",
    "not_ldn_not_crt_density=not_ldn_not_crt_density.merge(ur[['site', 'land_type_labels']], on='site', how='inner')\n",
    "# not_ldn_not_crt_density=not_ldn_not_crt_density.groupby('land_type_labels').mean().reset_index()\n",
    "\n",
    "\n",
    "# create sum of all POIs for each site\n",
    "not_ldn_not_crt_density['All POIs']= not_ldn_not_crt_density.iloc[:, 0:17].sum(axis=1)\n",
    "# crreate sum of all POIs excluding pubs\n",
    "not_ldn_not_crt_density['POIs Excluding Pubs']= not_ldn_not_crt_density.drop('amenity_pub', axis=1).iloc[:, 0:16].sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation by land type label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='All POIs', y='land_type_labels', data= not_ldn_not_crt.sort_values('All POIs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='All POIs', y='land_type_labels', data= not_ldn_not_crt_density.sort_values('All POIs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='POIs Excluding Pubs', y='land_type_labels', data= not_ldn_not_crt.sort_values('POIs Excluding Pubs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='POIs Excluding Pubs', y='land_type_labels', data= not_ldn_not_crt_density.sort_values('POIs Excluding Pubs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='amenity_pub', y='land_type_labels', data= not_ldn_not_crt.sort_values('amenity_pub'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='amenity_pub', y='land_type_labels', data= not_ldn_not_crt_density.sort_values('amenity_pub'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "req_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "73dd042dec22895802a5cf4c230cd0d0aa33a4e312107f26490806e8c532eb8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
